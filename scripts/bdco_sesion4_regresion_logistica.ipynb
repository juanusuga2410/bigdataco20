{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/macc-urosario/bigdataco20/main/scripts/data/red_blood_cells_csv.csv\")\n",
    "# df = pd.read_csv(\"data/red_blood_cells.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Area_cualitativa'] = df['Area'].apply(lambda x: 'High' if x>40000 else 'Low')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.loc[df['etiquetas']!='Drepanocits'].reset_index(drop=True)\n",
    "df2['etiquetas2'] = df2.etiquetas.factorize()[0] # Esferocito es 0\n",
    "df2['Area_cualitativa2'] = df2.Area_cualitativa.factorize()[0] # Low es 0\n",
    "\n",
    "df2.etiquetas.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos los descriptores de `MajorAxisLength` y `Mean_Green`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='MajorAxisLength', y='Mean_Green',hue='etiquetas', data=df2,alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='MajorAxisLength', x='etiquetas',data=df2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y='Mean_Green', x='etiquetas',data=df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué no usar regresión lineal?\n",
    "El modelo de regresión lineal por defecto, no es ideal y\n",
    "podría hacerse mejor simplemente haciendo que todas\n",
    "las probabilidades<0 sean igual a 0 y todas las\n",
    "probabilidades> 1 igual a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.regplot('MajorAxisLength', 'etiquetas2', data=df2)\n",
    "plt.ylabel('Normal RBC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, se debe encontrar una función que siempre limite la salida entre cero y uno. Una función que satiface esta condición es la función logística (también llamada sigmoid function). \n",
    "\n",
    "$$y = \\frac{e^{\\theta_0 + \\theta_1X}}{1 + e^{\\theta_0 + \\theta_1X}}$$\n",
    "\n",
    "Muchas veces verás la función sigmoide en un formato más simple:\n",
    "\n",
    "$$y = \\frac{1}{1 + e^{-t}}$$\n",
    "\n",
    "Donde $t$ es solo el modelo lineal normal $t = \\theta_0 + \\theta_1X$. Se puede usar algo de álgebra para mostrar que las dos ecuaciones anteriores son equivalentes\n",
    "\n",
    "Ahora se puede pensar a $y$ como la probabilidad dado un cierto valor de X ya que siempre estará entre 0 y 1. Se puede mostrar que $$log{\\frac{p(X)}{1 - p(X)}} = \\theta_0 + \\theta_1X$$\n",
    "\n",
    "Donde $y$ ha sido reemplazado por $p(X)$, la probabilidad de $X$. La expresión $ \\frac{p(X)}{1 - p (X)} $ se conoce como *odds*. Entonces, por ejemplo, si llegaron a la final el Barcelona y el Manchester City,  estás apostando y piensas que el Barcelona ganará la champions el 80% del tiempo. El odds sería .8 / .2 = 4 o dicho de otra forma \"4 a 1\". Por cada 4 veces que gana el Barcelona, el Manchester City ganará una vez.\n",
    "\n",
    "Lo que dice la regresión logística es que el *log odds* se modela mediante un modelo lineal que puede resolverse mediante regresión lineal. Esto tiene el significado literal de: dado un aumento de una unidad en una de las variables (por ejemplo, $ X_1 $), se producirá un aumento de $ \\theta_1 $ en el *log odds*. O de manera equivalente, el *log odds* se multiplicará por $ e ^ {\\theta_1} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = df2['MajorAxisLength'].values.reshape(-1,1) \n",
    "y = df2['etiquetas2']\n",
    "\n",
    "# Crea un array para el conjunto de test. Calcula la probabilidad\n",
    "# de clasificacion y la classificacion predicha.\n",
    "X_test = np.arange(df2.MajorAxisLength.min(), df2.MajorAxisLength.max()).reshape(-1,1)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y)\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "# Left plot\n",
    "sns.regplot(df2.MajorAxisLength, df2.etiquetas2, order=1, ci=None,\n",
    "            scatter_kws={'color':'orange'},\n",
    "            line_kws={'color':'blue', 'lw':2}, ax=ax1)\n",
    "# Right plot\n",
    "ax2.scatter(X_train, y, color='orange')\n",
    "ax2.plot(X_test, prob[:,1], color='blue')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.hlines(1, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.hlines(0, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.set_ylabel('Probability of normal RBC')\n",
    "    ax.set_xlabel('MajorAxisLength')\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.])\n",
    "    ax.set_xlim(left=150)\n",
    "    ax.set_ylim(top=1.1)\n",
    "    ax.set_ylim(bottom=-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística para normal RBC usando como predictor únicamente a `MajorAxisLength`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "X_train = df2[['MajorAxisLength']]\n",
    "\n",
    "y = df2['etiquetas']\n",
    "\n",
    "model.fit(X_train,y)\n",
    "\n",
    "print(\"classes: {}\\ncoefficientes: {}\\nintercepto: {}\".format(\n",
    "    model.classes_,model.coef_, model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefbonito(model,X):\n",
    "    D = dict(coeficientes=np.c_[model.intercept_,model.coef_].ravel())\n",
    "    return pd.DataFrame(D, index=['intercepto']+ X.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefbonito(model,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidad = np.exp(-17.277293+0.074146*200)/(1+np.exp(-17.277293+0.074146*200))\n",
    "print(f\"La probabilidad de que el glóbulo rojo sea normal es de {probabilidad:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[250]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística usando únicamente la variable cualitativa `Area_cualitativa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['etiquetas','Area_cualitativa', 'MajorAxisLength', 'Mean_Green']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "X_train = df2[['Area_cualitativa2']]\n",
    "y = df2['etiquetas']\n",
    "model.fit(X_train,y)\n",
    "\n",
    "coefbonito(model,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística múltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modulo \"preprocessing\" es muy importante en la vida real\n",
    "from sklearn import preprocessing\n",
    "\n",
    "model = LogisticRegression(C=1000)\n",
    "X_train = df2[['MajorAxisLength','Area_cualitativa2','Mean_Green']]\n",
    "\n",
    "# Se escalan los descriptores entre 0 y 1, para asegurar la convergencia.\n",
    "X2 = preprocessing.scale(X_train)\n",
    "y = df2['etiquetas']\n",
    "# model.fit(X_train,y)\n",
    "model.fit(X2,y)\n",
    "\n",
    "coefbonito(model,X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular y visualizar la matriz de confusion \n",
    "def plotCM(ytrue, ypred, clases=None, normalize = False, ax = None):\n",
    "    \"\"\" Funcion para calcular y visualizar la matriz de confusion\"\"\"\n",
    "    \n",
    "    if clases == None:\n",
    "        clases = list(set(ytrue))\n",
    "        clases.sort() # etiquetas unicas ordenadas alfabeticamente\n",
    "    \n",
    "    CM = confusion_matrix(ytrue,ypred, labels=clases)\n",
    "    \n",
    "    #Normaliza la matriz de confusion dividiendo cada fila por el total de verdaderos\n",
    "    if normalize:\n",
    "        CM = 100*CM / CM.sum(axis=1).reshape(-1,1) #Aprovechando el Broadcasting!\n",
    " \n",
    "    df = pd.DataFrame(CM, index=clases, columns=clases)\n",
    "    df.index.name = 'True'; df.columns.name = 'Predicted'\n",
    "    \n",
    "    sns.heatmap( df, # Visualizando la matriz de confusion\n",
    "             annot=True, fmt='2.1f', cmap='ocean_r',cbar=False,square=True, annot_kws={'fontsize':16}, ax=ax )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(y, model.predict(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = (515+498)/(515+498+54+37)\n",
    "print(f\"Se obtiene una exactitud de {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y,model.predict(X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Esta exactitud obtenida es un buen indicador del desempeño del modelo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. Porque estamos evaluando el desempeño sobre el mismo conjunto con el cual fue entrenado el modelo. Si el modelo ha memorizado muy bien los datos, estaríamos en un *sobre-ajuste* (overfitting) y resultaría en una exactitud muy alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['MajorAxisLength','Area_cualitativa2','Mean_Green']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,df2['etiquetas'], test_size=0.35, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a estandarizar los datos, pero esta vez, tenemos que tener en cuenta que se debe aplicar la misma transformación al conjunto de prueba `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() #Definimos el objeto que estandarizara\n",
    "scaler.fit(X_train) # ajustamos el scaler al training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression() # Modelo\n",
    "model.fit(scaler.transform(X_train), y_train) #Ajuste del modelo solo en training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Y  con las tres clases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística se puede a extender a más clases, realizando múltiples clasificadores binarios o modificando la función de costo para aplicarlo a múltiples clases (multinomial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial')\n",
    "X = df[['MajorAxisLength','Area','Mean_Green']]\n",
    "y = df['etiquetas']\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "acc = accuracy_score(y,y_pred)\n",
    "\n",
    "print(f\"La exactitud de clasificación es {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo podríamos mejorar la clasificación de los tres tipos de glóbulos rojos? \n",
    "\n",
    "Recuerda que hay que hacer una división training/test. Estandarizar las variables ayuda a mejorar y además, sólo hemos usado tres descriptores de los 28 que hay.\n",
    "\n",
    "Inténtalo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toma sólo las variables cuantitativas desde el `Area` hasta la `Entropy_B`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,'Area':'Entropy_B'] # Tomamos los descriptores cuantitativos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haz una división training/test con un `test_size=0.3` y una semilla `random_state=123`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA EL CODIGO AQUI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea un objeto de estandarización de las variables ajustado sobre el training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA EL CODIGO AQUI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ajusta un modelo de regresión logística sobre los datos del training set estandarizados y has una predicción sobre el test set (estandarizado).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA EL CODIGO AQUI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalúa el accuracy sobre las predicciones del test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA EL CODIGO AQUI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Muestra la matriz de confusión normalizada de la predicción sobre el test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCA EL CODIGO AQUI\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
